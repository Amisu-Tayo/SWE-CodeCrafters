{"nbformat": 4, "nbformat_minor": 5, "metadata": {}, "cells": [{"id": "b7dafffa", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "!pip install transformers datasets accelerate --quiet\n", "outputs": []}, {"id": "f487e8c3", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "from google.colab import files\nuploaded = files.upload()\n# Expecting a file named fabric_advisor_dataset.jsonl\n", "outputs": []}, {"id": "951f8026", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "from datasets import load_dataset\n\ndataset = load_dataset('json', data_files='fabric_advisor_dataset.jsonl', split='train')\ndataset = dataset.map(lambda x: {'text': f\"Input:\\n{x['input']}\\nOutput:\\n{x['output']}\"})\n\ndataset = dataset.train_test_split(test_size=0.1)\n", "outputs": []}, {"id": "4005c866", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\ntokenizer.pad_token = tokenizer.eos_token\n\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n\ntokenized = dataset.map(tokenize, batched=True)\n", "outputs": []}, {"id": "6a0847e8", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer\n\nmodel = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n\nargs = TrainingArguments(\n    output_dir=\"gpt2-fabric-advisor\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    save_total_limit=1,\n    save_strategy=\"epoch\",\n    logging_dir=\"logs\",\n)\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized[\"train\"],\n    eval_dataset=tokenized[\"test\"],\n    tokenizer=tokenizer,\n)\n\ntrainer.train()\n", "outputs": []}, {"id": "e53df558", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "model.save_pretrained(\"gpt2-fabric-advisor\")\ntokenizer.save_pretrained(\"gpt2-fabric-advisor\")\n\n# Download\n!zip -r gpt2-fabric-advisor.zip gpt2-fabric-advisor\nfiles.download(\"gpt2-fabric-advisor.zip\")\n", "outputs": []}]}